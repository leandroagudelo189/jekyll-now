---
layout: default
---



<div class="bg">
  <img src="{{ site.baseurl }}/images/nebula.jpg"> 
</div>






<p>
 
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
</p>


<h1>Research</h1>
<div class="post">
<blockquote>
“The more important reason is that research itself provides an important long-run perspective on the issues we face on a day-to-day basis.” -Ben Bernanke
</blockquote>
</div>


<p> 
<br>
<br>
<br>
<br>
<br>
<br>
Existing machine and deep learning models lack allostatic strategies. In addition, current systems offer <br>
great performance in narrow environment or applications. This means deep reinforcement learning or <br>
evolutionary strategies fail to integrate responses across multiple non-related environments. In fact, there is <br>
no viable long-term memory approach for multi-environment integration. Training these systems remains <br>
very expensive, even for approaches that mimic natural selection such as genetic algorithms.  <br>
<br>
Interestingly, biological systems have developed solutions for integrating massive tons of data with genetically <br>
encoded responses. These responses can last many generations and can in fact be used in different environments. <br>
There are many molecular solutions that have been shaped through thousands of years to offer better <br>
evolutionary outcomes. Some of the more impactful adaptations are comparmentalization of specific tasks,<br>
development of low entropy models and transcriptional encoding of information for memory recall. <br>
<br>
In line with this, we aim at integrating evolutionary adaptations observed in biological systems with machine <br>
and deep learning models. We believe that this scientific journey is a step closer to the generation of allostatic<br>
agents with the ability to emulate transcriptional encoding. <br>
<br>
<br>
<br>
</p>


