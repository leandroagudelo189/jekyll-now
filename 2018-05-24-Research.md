---
layout: research
title: ''
published: true
---
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
# Research 
<div class="post">
<blockquote>
“The more important reason is that research itself provides an important long-run perspective on the issues we face on a day-to-day basis.” -Ben Bernanke
</blockquote>
</div>

<br>
<br>
<br>
Existing machine and deep learning models lack allostatic strategies. In addition, current systems offer 
great performance in narrow environment or applications. This means deep reinforcement learning or 
evolutionary strategies fail to integrate responses across multiple non-related environments. In fact, there is 
no viable long-term memory approach for multi-environment integration. Training these systems remains 
very expensive, even for approaches that mimic natural selection such as genetic algorithms. 
<br>
<br>
Interestingly, biological systems have developed solutions for integrating massive tons of data with  
genetically encoded responses. These responses can last many generations and can in fact be used in  
different environments. There are many molecular solutions that have been shaped through thousands of 
years to offer better evolutionary outcomes. Some of the more impactful adaptations are 
comparmentalization of specific tasks, development of low entropy models and transcriptional encoding 
of information. 
  <br>
  <br>
In line with this, we aim at integrating evolutionary adaptations observed in biological systems with machine 
and deep learning models. We believe that this scientific journey is a step closer to the generation of 
allostatic agents with the ability to emulate transcriptional encoding. 


