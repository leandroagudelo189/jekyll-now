---
published: true
---
### Supervised deep learning (sequence models)

Intuition on recurrent neural networks (Study notes)


![an image alt text]({{ leandroagudelo189.github.io/tree/master }}/images/rnn1.jpg "an image title")
----
****

![an image alt text]({{ leandroagudelo189.github.io/tree/master }}/images/rnn2.jpg "an image title")
----
****

### Further reading

[Learning long-term dependencies with gradient descent is difficult](http://ai.dinfo.unifi.it/paolo//ps/tnn-94-gradient.pdf), by Bengio et al. 

[On the difficulty of training recurrent neural networks](http://proceedings.mlr.press/v28/pascanu13.pdf), by Pascanu et al.

[Long Short-Term memory](http://www.bioinf.jku.at/publications/older/2604.pdf), by Hochreiter et al.

[Understanding LSTMs](http://colah.github.io/posts/2015-08-Understanding-LSTMs/), by Olah

[LSTMs and its diagrams](https://medium.com/mlreview/understanding-lstm-and-its-diagrams-37e2f46f1714), by Shi Yan

[RNN's unreasonble effect](http://karpathy.github.io/2015/05/21/rnn-effectiveness/), by Karpathy

[LSTM: A Search Space Odyssey](https://arxiv.org/pdf/1503.04069.pdf), by Greff et al.

[Deep Sparse Rectifier Neural Networks](http://proceedings.mlr.press/v15/glorot11a/glorot11a.pdf), by Glorot et al.


### Implementation of RNN

